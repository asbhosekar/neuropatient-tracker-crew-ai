# LLM Provider Configuration
# Options: "openai" or "local"
LLM_PROVIDER=local

# OpenAI API Configuration (when LLM_PROVIDER=openai)
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4o-mini

# Local LLM Configuration (when LLM_PROVIDER=local)
# Default is LM Studio endpoint - adjust if using Ollama or other
LOCAL_LLM_BASE_URL=http://localhost:1234/v1
LOCAL_LLM_MODEL=llama-3.2-3b-instruct
LOCAL_LLM_API_KEY=not-needed

# Database Configuration
DATABASE_URL=sqlite:///./neuro_tracker.db

# Application Settings
DEBUG=true
LOG_LEVEL=INFO
